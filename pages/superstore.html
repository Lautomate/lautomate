<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv='cache-control' content='no-cache'> 
    <meta http-equiv='expires' content='0'> 
    <meta http-equiv='pragma' content='no-cache'>
    <link rel="icon" href="../src/vector_inkscape.ico" type="image/x-icon">
    <link rel="stylesheet" href="../styles/projects.css">
    <title>Lau Portfolio</title>
</head>
<body>
    <div class="wrapper">
        <div>
            <iframe title="Superstore" width="600" height="373.5" src="https://app.powerbi.com/view?r=eyJrIjoiYWQ5YWUzOTEtYWE2MS00NjNjLWI5MGItOGJhZmQxOTU1YWJjIiwidCI6IjBjYjc0NWI5LTE2OWYtNDgwOC05YjQxLTgzNDY5MmJmNTc2NSIsImMiOjEwfQ%3D%3D" frameborder="0" allowFullScreen="true"></iframe>
        </div>
        <div>
            <h1 id="title">Superstore</h1>
            <p id="difficulty" class="upper-bound">Level: Intermediate</p>
            <p id="tools" class="upper-bound">Tools: Python, SQL, Power Query, DAX, Power BI</p>
            <p id="topic" class="upper-bound">Topic: Sales and Profits</p>
            <p class="description">I downloaded the dataset from Kaggle and created a <span>Python script</span> to <span>upload</span> it to SQL. 
                In SQL, I first created a view for customers and then for products to serve as dimensions for later analysis. 
                Extracting unique values for the location dimension proved challenging due to the presence of cities with the same name in different states. 
                To address this, I created a <span>connector</span> by combining the city and state into a <span>single unique identifier</span>.</p>
            </p>
            <p class="description">My final step in SQL involved creating a fact table view for superstore transactions. 
                This view includes only relevant columns while removing those that are part of the dimension tables, ensuring a streamlined dataset for analysis.</p>
            <p class="description">I then targeted all the views from SQL for use in Power BI. After loading the data into Power Query, I ensured that all data 
                types were correct and utilized <span>column profiling</span> to verify <span>data integrity</span>. I also renamed tables for better clarity. 
                Whenever I encountered a date column in my data source, I immediately created a date dimension directly in Power Query to facilitate time-based analysis.</p>
            <p class="description"><span>Data modeling</span> became relatively straightforward since I <span>transformed the data upstream</span> and performed <span>necessary transformations downstream</span>. 
                I consistently checked for any blank values in the primary key columns of the dimension tables to confirm the accuracy of my data modeling.</p>
            <p class="description">Given that this dataset is based in the U.S., the currency format is in dollars. 
                This project incorporates <span>basic arithmetic DAX calculations</span> while focusing on fundamental <span>basic table functions</span> within DAX.</p>
            <p class="description">Overall, my approach emphasizes a robust data preparation process, ensuring that the data is clean and well-structured for effective analysis in Power BI.</p>
        </div>

    </div>
</body>
</html>